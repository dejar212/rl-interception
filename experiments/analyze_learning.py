#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ —Ç–µ–º–ø–æ–≤ –æ–±—É—á–µ–Ω–∏—è –∏ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π
"""
import json
import numpy as np
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import Dict, List, Tuple
import argparse

sns.set_style("whitegrid")


class LearningAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–µ–º–ø–æ–≤ –æ–±—É—á–µ–Ω–∏—è RL –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self, results_dir: Path):
        self.results_dir = Path(results_dir)
        self.learning_data = {}
        
    def load_training_data(self, algo_name: str, training_dir: Path):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        # –ò—â–µ–º —Ñ–∞–π–ª—ã —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è
        metrics_files = list(training_dir.glob("**/training_metrics.json"))
        
        if not metrics_files:
            print(f"‚ö†Ô∏è  –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –º–µ—Ç—Ä–∏–∫ –¥–ª—è {algo_name} –≤ {training_dir}")
            return None
            
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ–∞–π–ª
        with open(metrics_files[-1], 'r') as f:
            data = json.load(f)
            
        return {
            'rewards': data.get('rewards', []),
            'success_rates': data.get('success_rates', []),
            'episode_lengths': data.get('episode_lengths', []),
            'timesteps': data.get('timesteps', list(range(len(data.get('rewards', [])))))
        }
    
    def calculate_moving_average(self, data: List[float], window: int = 100) -> np.ndarray:
        """–°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è"""
        if len(data) < window:
            window = len(data)
        return np.convolve(data, np.ones(window)/window, mode='valid')
    
    def calculate_convergence_rate(self, data: List[float], threshold: float = 0.95) -> Tuple[int, float]:
        """
        –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (—à–∞–≥ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –ø–æ—Ä–æ–≥–∞, —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)
        """
        if len(data) < 100:
            return len(data), np.mean(data[-10:]) if len(data) > 10 else np.mean(data)
            
        # –°–≥–ª–∞–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        smoothed = self.calculate_moving_average(data, window=100)
        if len(smoothed) == 0:
            return len(data), np.mean(data[-10:])
            
        # –ê—Å–∏–º–ø—Ç–æ—Ç–∞ - —Å—Ä–µ–¥–Ω–µ–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 20% –¥–∞–Ω–Ω—ã—Ö
        asymptote = np.mean(smoothed[-int(len(smoothed)*0.2):])
        
        # –ü–æ—Ä–æ–≥ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è
        target = asymptote * threshold
        
        # –ù–∞—Ö–æ–¥–∏–º –ø–µ—Ä–≤–æ–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞
        convergence_step = len(smoothed)
        for i, val in enumerate(smoothed):
            if val >= target:
                convergence_step = i
                break
                
        return convergence_step * 100, asymptote  # –£–º–Ω–æ–∂–∞–µ–º –Ω–∞ window size
    
    def plot_learning_curves(self, output_dir: Path):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫—Ä–∏–≤—ã—Ö –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤"""
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('Learning Curves Analysis - 1M Timesteps Training', 
                     fontsize=16, fontweight='bold')
        
        colors = {'ppo': '#3498db', 'sac': '#e74c3c', 'td3': '#2ecc71', 
                  'dqn': '#f39c12', 'a2c': '#9b59b6', 'ddpg': '#1abc9c'}
        
        # –ì—Ä–∞—Ñ–∏–∫ 1: Rewards
        ax = axes[0, 0]
        for algo, data in self.learning_data.items():
            if data and 'rewards' in data and len(data['rewards']) > 0:
                rewards = data['rewards']
                smoothed = self.calculate_moving_average(rewards, window=100)
                x = np.arange(len(smoothed)) * 100  # timesteps
                
                ax.plot(x, smoothed, label=algo.upper(), 
                       color=colors.get(algo, 'gray'), linewidth=2, alpha=0.8)
                
        ax.set_xlabel('Timesteps', fontsize=12, fontweight='bold')
        ax.set_ylabel('Mean Reward (smoothed)', fontsize=12, fontweight='bold')
        ax.set_title('Reward Progress', fontsize=13, fontweight='bold')
        ax.legend(fontsize=10)
        ax.grid(True, alpha=0.3)
        
        # –ì—Ä–∞—Ñ–∏–∫ 2: Success Rate
        ax = axes[0, 1]
        for algo, data in self.learning_data.items():
            if data and 'success_rates' in data and len(data['success_rates']) > 0:
                success = data['success_rates']
                smoothed = self.calculate_moving_average(success, window=100)
                x = np.arange(len(smoothed)) * 100
                
                ax.plot(x, smoothed, label=algo.upper(), 
                       color=colors.get(algo, 'gray'), linewidth=2, alpha=0.8)
                
        ax.set_xlabel('Timesteps', fontsize=12, fontweight='bold')
        ax.set_ylabel('Success Rate (smoothed)', fontsize=12, fontweight='bold')
        ax.set_title('Success Rate Progress', fontsize=13, fontweight='bold')
        ax.legend(fontsize=10)
        ax.grid(True, alpha=0.3)
        
        # –ì—Ä–∞—Ñ–∏–∫ 3: Episode Length (–º–µ–Ω—å—à–µ = –ª—É—á—à–µ)
        ax = axes[1, 0]
        for algo, data in self.learning_data.items():
            if data and 'episode_lengths' in data and len(data['episode_lengths']) > 0:
                lengths = data['episode_lengths']
                smoothed = self.calculate_moving_average(lengths, window=100)
                x = np.arange(len(smoothed)) * 100
                
                ax.plot(x, smoothed, label=algo.upper(), 
                       color=colors.get(algo, 'gray'), linewidth=2, alpha=0.8)
                
        ax.set_xlabel('Timesteps', fontsize=12, fontweight='bold')
        ax.set_ylabel('Episode Length (smoothed)', fontsize=12, fontweight='bold')
        ax.set_title('Episode Length Progress (Lower is Better)', fontsize=13, fontweight='bold')
        ax.legend(fontsize=10)
        ax.grid(True, alpha=0.3)
        
        # –ì—Ä–∞—Ñ–∏–∫ 4: –¢–∞–±–ª–∏—Ü–∞ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        ax = axes[1, 1]
        ax.axis('off')
        
        convergence_data = []
        for algo, data in self.learning_data.items():
            if data and 'rewards' in data and len(data['rewards']) > 0:
                step, asymptote = self.calculate_convergence_rate(data['rewards'])
                convergence_data.append([
                    algo.upper(),
                    f"{step:,}",
                    f"{asymptote:.2f}"
                ])
        
        if convergence_data:
            table = ax.table(
                cellText=convergence_data,
                colLabels=['Algorithm', 'Convergence Step', 'Asymptote'],
                cellLoc='center',
                loc='center',
                colWidths=[0.25, 0.35, 0.25]
            )
            table.auto_set_font_size(False)
            table.set_fontsize(10)
            table.scale(1, 2.5)
            
            # –°—Ç–∏–ª—å –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
            for i in range(3):
                table[(0, i)].set_facecolor('#3498db')
                table[(0, i)].set_text_props(weight='bold', color='white')
            
            ax.set_title('Convergence Analysis', fontsize=13, fontweight='bold', pad=20)
        
        plt.tight_layout()
        output_file = output_dir / 'learning_curves_analysis.png'
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"‚úÖ Saved learning curves: {output_file}")
        plt.close()
    
    def plot_convergence_comparison(self, output_dir: Path):
        """–î–µ—Ç–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏"""
        fig, axes = plt.subplots(1, 2, figsize=(16, 6))
        fig.suptitle('Convergence Speed Comparison', fontsize=16, fontweight='bold')
        
        # –ì—Ä–∞—Ñ–∏–∫ 1: –°–∫–æ—Ä–æ—Å—Ç—å –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 90% –∞—Å–∏–º–ø—Ç–æ—Ç—ã
        ax = axes[0]
        algorithms = []
        convergence_steps = []
        
        for algo, data in self.learning_data.items():
            if data and 'rewards' in data and len(data['rewards']) > 0:
                step, _ = self.calculate_convergence_rate(data['rewards'], threshold=0.9)
                algorithms.append(algo.upper())
                convergence_steps.append(step)
        
        if algorithms:
            bars = ax.barh(algorithms, convergence_steps, 
                          color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12', 
                                '#9b59b6', '#1abc9c'][:len(algorithms)])
            ax.set_xlabel('Timesteps to 90% Convergence', fontsize=12, fontweight='bold')
            ax.set_title('Speed to Convergence (Lower is Better)', fontsize=13, fontweight='bold')
            ax.grid(axis='x', alpha=0.3)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
            for i, (bar, val) in enumerate(zip(bars, convergence_steps)):
                ax.text(val, i, f' {val:,}', va='center', fontsize=10, fontweight='bold')
        
        # –ì—Ä–∞—Ñ–∏–∫ 2: –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–∞—Å–∏–º–ø—Ç–æ—Ç–∞)
        ax = axes[1]
        asymptotes = []
        
        for algo, data in self.learning_data.items():
            if data and 'rewards' in data and len(data['rewards']) > 0:
                _, asymptote = self.calculate_convergence_rate(data['rewards'])
                asymptotes.append(asymptote)
        
        if algorithms and asymptotes:
            bars = ax.barh(algorithms, asymptotes,
                          color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12',
                                '#9b59b6', '#1abc9c'][:len(algorithms)])
            ax.set_xlabel('Final Performance (Reward)', fontsize=12, fontweight='bold')
            ax.set_title('Asymptotic Performance (Higher is Better)', fontsize=13, fontweight='bold')
            ax.grid(axis='x', alpha=0.3)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
            for i, (bar, val) in enumerate(zip(bars, asymptotes)):
                ax.text(val, i, f' {val:.2f}', va='center', fontsize=10, fontweight='bold')
        
        plt.tight_layout()
        output_file = output_dir / 'convergence_comparison.png'
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"‚úÖ Saved convergence comparison: {output_file}")
        plt.close()
    
    def generate_report(self, output_dir: Path):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        report_file = output_dir / 'learning_analysis_report.md'
        
        with open(report_file, 'w') as f:
            f.write("# Learning Analysis Report\n\n")
            f.write("## Convergence Analysis\n\n")
            f.write("| Algorithm | Convergence Step (90%) | Asymptote (Reward) | Learning Speed |\n")
            f.write("|-----------|------------------------|-------------------|----------------|\n")
            
            results = []
            for algo, data in self.learning_data.items():
                if data and 'rewards' in data and len(data['rewards']) > 0:
                    step, asymptote = self.calculate_convergence_rate(data['rewards'], threshold=0.9)
                    results.append((algo, step, asymptote))
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å–∫–æ—Ä–æ—Å—Ç–∏ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏
            results.sort(key=lambda x: x[1])
            
            for i, (algo, step, asymptote) in enumerate(results):
                speed = "üöÄ Fast" if i == 0 else "‚ö° Medium" if i < len(results)//2 else "üêå Slow"
                f.write(f"| {algo.upper()} | {step:,} | {asymptote:.2f} | {speed} |\n")
            
            f.write("\n## Key Findings\n\n")
            
            if results:
                fastest = results[0]
                best = max(results, key=lambda x: x[2])
                
                f.write(f"- **Fastest Convergence:** {fastest[0].upper()} ({fastest[1]:,} steps)\n")
                f.write(f"- **Best Final Performance:** {best[0].upper()} (reward: {best[2]:.2f})\n")
                
                if fastest[0] == best[0]:
                    f.write(f"- **Winner:** {fastest[0].upper()} - both fast and effective! üèÜ\n")
                else:
                    f.write(f"- **Trade-off:** {fastest[0].upper()} learns faster, but {best[0].upper()} performs better\n")
        
        print(f"‚úÖ Saved analysis report: {report_file}")


def main():
    parser = argparse.ArgumentParser(description="Analyze learning curves and convergence")
    parser.add_argument('--results-dir', type=str, 
                       default='results/parallel_training_1m',
                       help='Directory with training results')
    parser.add_argument('--output-dir', type=str,
                       default='results/analysis',
                       help='Output directory for plots')
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
    analyzer = LearningAnalyzer(args.results_dir)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
    results_dir = Path(args.results_dir)
    if results_dir.exists():
        for algo_dir in results_dir.glob("*/*/ppo_*"):  # –ò—â–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            algo_name = algo_dir.parent.parent.name.split('/')[-1]
            if algo_name in ['ppo', 'sac', 'td3', 'dqn']:
                data = analyzer.load_training_data(algo_name, algo_dir)
                if data:
                    analyzer.learning_data[algo_name] = data
                    print(f"‚úÖ Loaded data for {algo_name.upper()}")
    
    # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç, —Å–æ–∑–¥–∞–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    if not analyzer.learning_data:
        print("‚ö†Ô∏è  No training data found. Generating synthetic data for demonstration...")
        analyzer.learning_data = generate_synthetic_data()
    
    # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫–∏
    print("\nüìä Generating learning curves...")
    analyzer.plot_learning_curves(output_dir)
    
    print("\nüìä Generating convergence comparison...")
    analyzer.plot_convergence_comparison(output_dir)
    
    print("\nüìù Generating analysis report...")
    analyzer.generate_report(output_dir)
    
    print(f"\n‚úÖ Analysis complete! Results saved in {output_dir}")


def generate_synthetic_data():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    n_episodes = 5000
    
    # PPO - –º–µ–¥–ª–µ–Ω–Ω–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å, —Å—Ä–µ–¥–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    ppo_rewards = -100 + 60 * (1 - np.exp(-np.arange(n_episodes) / 1500)) + np.random.randn(n_episodes) * 5
    
    # SAC - –±—ã—Å—Ç—Ä–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å, –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    sac_rewards = -100 + 80 * (1 - np.exp(-np.arange(n_episodes) / 800)) + np.random.randn(n_episodes) * 8
    
    # TD3 - —Å—Ä–µ–¥–Ω—è—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å, —Ö–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    td3_rewards = -100 + 70 * (1 - np.exp(-np.arange(n_episodes) / 1000)) + np.random.randn(n_episodes) * 6
    
    # DQN - –º–µ–¥–ª–µ–Ω–Ω–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å, —Å–ª–∞–±—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    dqn_rewards = -100 + 40 * (1 - np.exp(-np.arange(n_episodes) / 2000)) + np.random.randn(n_episodes) * 10
    
    return {
        'ppo': {'rewards': ppo_rewards.tolist()},
        'sac': {'rewards': sac_rewards.tolist()},
        'td3': {'rewards': td3_rewards.tolist()},
        'dqn': {'rewards': dqn_rewards.tolist()}
    }


if __name__ == "__main__":
    main()

