# Длительное обучение PPO - 1M timesteps

algorithm:
  name: "PPO"
  
  # Увеличенная архитектура для лучшего обучения
  hidden_dim: 256                   # Увеличено с 128
  
  # Гиперпараметры обучения
  learning_rate: 0.0003
  gamma: 0.99
  gae_lambda: 0.95
  
  # PPO специфичные
  clip_coef: 0.2
  vf_coef: 0.5
  ent_coef: 0.01
  max_grad_norm: 0.5
  
  # Параметры обучения - 1M timesteps
  total_timesteps: 1000000          # Увеличено с 200K
  num_steps: 2048                   # Rollout size
  batch_size: 64
  num_epochs: 10
  
  device: "cpu"


